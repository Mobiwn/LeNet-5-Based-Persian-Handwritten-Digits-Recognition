# -*- coding: utf-8 -*-
"""PresianDigitsRecognitionWithLeNet5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17Vq-TFUHfugtvTP9Q3jtUq2xS4nNOs99

# Persian Handwritten Digit Recognition With LeNet-5

**Author:** Mobin Kheibary  
**Date:** January, 2024

## Introduction

This project focuses on the classification of Persian handwritten digits using the LeNet-5 convolutional neural network. The dataset comprises 150,000 images, with 15,000 images per class, covering the complete range of Persian digits from 0 to 9. Each image is standardized to a size of 28 x 28 pixels, with a single channel, and is provided in JPG format. The LeNet-5 model, initially designed for identifying handwritten zip code numbers in 1998, is employed for the classification task.

## Dataset Overview

- **Images:** 150,000
- **Images per class:** 15,000
- **Image dimensions:** 28 x 28 pixels
- **Channels:** 1
- **Format:** JPG

## Data Source

The dataset is obtained from Kaggle and is accessible [here](https://www.kaggle.com/datasets/amirmahdiabbootalebi/persian-handwritten-digits).

## Notebook Content

1. **Set Up Environment & Read Dataset:** Download the dataset and import the necessary modules. Analyze the distribution of images in both the training and testing datasets.

2. **Generate Training and Testing Data:** Prepare the data for training and evaluation.

3. **Data Preprocessing:** Implement preprocessing steps to enhance the model's performance.

4. **Define & Train LeNet-5 Model:** Configure and train the LeNet-5 model on the prepared dataset.

5. **Evaluate Performance:** Assess the model's performance on the testing dataset.

6. **Conclusion:** Summarize findings and potential areas for improvement.

The project aims to establish a robust model for recognizing Persian handwritten digits and contributes to the broader field of image classification using deep learning techniques.
"""

!pip install opendatasets
import opendatasets as od

try:
    od.download('https://www.kaggle.com/datasets/amirmahdiabbootalebi/persian-handwritten-digits', force=False)
    print('Dataset downloaded')
except ImportError:
    print('Download failed')

import os
from random import choice
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

# from google.colab import drive
# import os

# # Mount Google Drive
# drive.mount('/content/drive')

# # Define file paths
# train_dir = '/content/drive/My Drive/persian_numbers/persian-handwritten-digits/Train/'
# test_dir = '/content/drive/My Drive/persian_numbers/persian-handwritten-digits/Test/'

train_dir = 'C:/Users/.../persian_numbers/persian-handwritten-digits/Train/'
test_dir = 'C:/Users/.../persian_numbers/persian-handwritten-digits/Test/'

def dataset_distribution():
    filelist = os.listdir(train_dir)

    print('Image distribution in train dataset:')
    for i in filelist:
        print(f'{i}: {len(os.listdir(train_dir + str(i)))} images')

    filelist = os.listdir(test_dir)

    print('\nImage distribution in test dataset:')
    for i in filelist:
        print(f'{i}: {len(os.listdir(test_dir + str(i)))} images')

dataset_distribution()

def display_images():
    fig, axs = plt.subplots(2, 5, figsize=(8, 4), tight_layout=True)
    for i in range(10):
        class_dir = os.listdir(train_dir + '/class_' + str(i))
        image_filename = choice(class_dir)
        image_path = train_dir + '/class_' + str(i) + '/' + image_filename
        #image = imread(image_path)
        image = Image.open(image_path)
        img = axs[int(i >= 5), i % 5].imshow(image, cmap='gray')
        img.axes.axis('on')
        img.axes.set_title(f'Digit: {i}')
    plt.show()

display_images()

"""## 2. Generate Training and Testing Data

To facilitate deep learning processes, we will undertake the subsequent steps for each subset:

* Gather and catalog paths to all images.
* Convert images into individual NumPy arrays and concatenate them into a unified array.
* Create image labels and concatenate them into a singular vector (one-dimensional array).
* Shuffle the elements within the arrays to ensure that images align with their respective labels.

"""

def get_paths(dataset):
    if dataset == 'train':
        filelist = os.listdir(train_dir)

        # lists paths in 'train_dir'
        paths = []
        for x in filelist:
            if x.startswith('class_'):
                paths.append(train_dir + x + '/')

        all_images = []

        # lists JPG files in all directories
        for i in paths:
            filelist_2 = os.listdir(i)
            for j in filelist_2:
                if j.endswith('.jpg'):
                    all_images.append(i + j)

    if dataset == 'test':
        filelist = os.listdir(test_dir)

        # lists paths in 'test_dir'
        path = []
        for x in filelist:
            if x.startswith('class_'):
                path.append(test_dir + x + '/')

        all_images = []

        # lists JPG files in all directories
        for i in path:
            filelist_2 = os.listdir(i)
            for j in filelist_2:
                if j.endswith('.jpg'):
                    all_images.append(i + j)

    return all_images

train_paths = get_paths(dataset='train')
test_paths = get_paths(dataset='test')

def generate_train_data():
    # prepare train images
    train_images = []

    for i in train_paths:
        image = Image.open(i)
        train_images.append(np.asarray(image))

    # generate train labels
    train_labels = []

    for i in range(10):
        train_labels.append([i] * 10_000)

    flat_list = []
    for row in train_labels:
        flat_list.extend(row)

    return np.array(train_images), np.array(flat_list)

X_train, y_train = generate_train_data()

print('Training images:', len(X_train))
print('Training labels:', len(y_train))

def generate_test_data():
    # prepare test images
    test_images = []

    for i in test_paths:
        image = Image.open(i)
        test_images.append(np.asarray(image))

    # generate test labels
    test_labels = []

    for i in range(10):
        test_labels.append([i] * 5_000)

    flat_list = []
    for row in test_labels:
        flat_list.extend(row)

    return np.array(test_images), np.array(flat_list)

X_test, y_test = generate_test_data()

print('Testing images:', len(X_test))
print('Testing labels:', len(y_test))

# shuffle train & test subsets
def unison_array_shuffle(a, b):
    assert len(a) == len(b)
    p = np.random.permutation(len(a))
    return a[p], b[p]

X_train, y_train = unison_array_shuffle(X_train, y_train)
X_test, y_test = unison_array_shuffle(X_test, y_test)

plt.figure(figsize=(4, 1))

plt.subplot(1, 3, 1)
plt.imshow(X_train[1200], interpolation='nearest')
plt.title('Label:' + str(y_train[1200]))

plt.subplot(1, 3, 2)
plt.imshow(X_test[1300], interpolation='nearest')
plt.title('Label:' + str(y_test[1300]))

plt.subplot(1, 3, 3)
plt.imshow(X_test[10], interpolation='nearest')
plt.title('Label:' + str(y_test[10]))
plt.show()

"""## 3. Data Preprocessing

During this phase, we will partition our dataset into training and validation sets using an 80:20 ratio. Additionally, we will augment the array dimensions for images by adding a new axis to represent the image channel. Finally, normalization will be applied to ensure values fall within the range [0, 1].

"""

# split data
X_val, y_val = X_train[80_000:, ..., np.newaxis], y_train[80_000:]
X_train, y_train = X_train[:80_000, ..., np.newaxis], y_train[:80_000]
X_test = X_test[..., np.newaxis]

# normalize data
X_train, X_val, X_test = X_train/255.0, X_val/255.0, X_test/255.0
X_train -= np.mean(X_train)
X_val -= np.mean(X_val)
X_test -= np.mean(X_test)

print('Final image shape:', X_train[0].shape, end='\n\n')
print('Training samples:', len(X_train))
print('Validation samples:', len(X_val))
print('Testing samples:', len(X_test))

"""## 4. Define & Train LeNet-5 Model

LeNet-5 stands as one of the pioneering convolutional neural networks, initially designed for identifying handwritten numbers. Its architecture and assumptions encompass:

* Two convolutional layers.
* Three fully connected layers.
* Two average pooling layers.
* Tanh activation function within hidden layers.
* Softmax activation function in the output layer.
* Cross-entropy serving as the cost function.
* Stochastic gradient descent employed as the optimizer.
* Convergence typically achieved after 10â€“12 epochs.
* Minimum error rate targeted at 0.95 on the test set (with accuracy monitored as the metric during the learning process).

As Keras Applications lacks a pre-defined LeNet-5 model, we will construct it from scratch, referencing the following [example](https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Comparison_image_neural_networks.svg/1920px-Comparison_image_neural_networks.svg.png).

"""

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense
from tensorflow.keras.optimizers import SGD

# define and build the model's architecture
def lenet5_architecture():
    model = Sequential(
        [
            Conv2D(filters=6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=(28, 28, 1), padding='valid'),

            AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),

            Conv2D(filters=16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'),

            AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),

            Flatten(),

            Dense(units=120, activation='tanh'),

            Dense(units=84, activation='tanh'),

            Dense(units=10, activation='softmax')
        ], name='LeNet-5'
    )

    # define optimizer & compile the model
    sgd_opt = SGD(learning_rate=0.01, momentum=0.0, decay=0.0)
    model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd_opt, metrics=['accuracy'])

    return model

LeNet5_model = lenet5_architecture()

# display the network's summary
LeNet5_model.summary()

# display optimizer params
#LeNet5_model.optimizer.get_config()

# train CNN
history = LeNet5_model.fit(x=X_train, y=y_train, validation_data=(X_val, y_val), epochs=20)

"""## 5. Evaluate Performance

We now transition to the crucial phase of testing our model and making predictions.
"""

def diagnosis_plots():
    metric_list =  ['loss', 'accuracy']
    epochs = len(history.history['loss']) + 1

    plt.figure(figsize=(12, 3))

    for i, metric in enumerate(metric_list):
        plt.subplot(1, 2, i + 1)
        plt.plot(range(1, epochs), history.history[metric], label='train')
        plt.plot(range(1, epochs), history.history['val_' + metric], label='test')
        plt.title('model ' + metric)
        plt.legend(loc='best')
        plt.xticks(range(0, epochs, 4))
        plt.xlabel('epoch')
        plt.ylabel('cost')
    plt.show()

diagnosis_plots()

from pandas import DataFrame
from sklearn.metrics import classification_report, confusion_matrix
from seaborn import heatmap

def classification_reports():
    # make predictions and retrieve their indexes
    predictions = LeNet5_model.predict(X_test)
    y_pred = np.argmax(predictions, axis=1)

    # print classification report
    print(DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose())

    # plot confusion matrix
    plt.figure(figsize=(6, 6))
    cm = confusion_matrix(y_test, y_pred, normalize='true')
    heatmap(cm, annot=True, cmap='Reds', fmt='.2f', square=True, cbar=False)
    plt.xlabel('predicted')
    plt.ylabel('true')
    plt.title('Normalized Confusion Matrix')
    plt.show()

classification_reports()

"""### 6. Conclusion

Among the Persian handwritten digits, distinguishing between twos and threes posed the greatest challenge, owing to their striking resemblance. Conversely, the remaining digits exhibited near-perfect prediction rates.

The primary objective of this notebook was to address a classification task involving Persian handwritten digits using a convolutional neural network. By constructing a CNN from scratch and leveraging the LeNet-5 architecture, we achieved commendable results. Despite its simplicity and age, the evaluation underscores the efficacy of LeNet-5 on this dataset, affirming its continued relevance and utility.

**References:**

* LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition. [Full Text](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)
* LeNet-5 Architecture. Retrieved from: https://en.wikipedia.org/wiki/LeNet [Accessed: 29.11.2023]
* LeNet-5 Architecture Explained. Retrieved from: https://hackmd.io/@machine-learning/S1WvJyqmI [Accessed: 29.11.2023]
* Siddhesh, B. (2023). LeNet-5 Architecture Explained. Retrieved from: https://medium.com/@siddheshb008/lenet-5-architecture-explained-3b559cb2d52b [Accessed: 29.11.2023]

"""

